{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ecabc5-2b8d-4128-be29-2b551744f1f4",
   "metadata": {},
   "source": [
    "## Graphical User Interface for Image Coloration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68507f5-d1fb-4453-985d-c4a6e588215e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/CPU:0'):\n",
    "    import tkinter as tk\n",
    "    from tkinter import filedialog\n",
    "    from PIL import Image, ImageTk\n",
    "    import torch\n",
    "    from torch import nn, optim\n",
    "    import torchvision.transforms as transforms\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "    from tqdm.notebook import tqdm\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage.color import rgb2lab, lab2rgb\n",
    "    SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e934436-ff77-40cc-ab05-7927feff4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.transforms = transforms.Resize((SIZE,SIZE), Image.BICUBIC)\n",
    "        self.size = SIZE\n",
    "        self.paths = paths\n",
    "    def __getitem__(self,idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\")\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        l = img_lab[[0], ...]/50. - 1.\n",
    "        ab = img_lab[[1,2], ...]/110.\n",
    "        return {'L':l, 'ab':ab}\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "def make_dataloaders(batch_size=1, **kwargs):\n",
    "    dataset = ColorizationDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader\n",
    "class UnetBlock(nn.Module):\n",
    "  def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
    "              innermost=False, outermost=False):\n",
    "      super().__init__()\n",
    "      self.outermost = outermost\n",
    "      if input_c is None: input_c = nf\n",
    "      downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
    "                          stride=2, padding=1, bias=False)\n",
    "      downrelu = nn.LeakyReLU(0.2, True)\n",
    "      downnorm = nn.BatchNorm2d(ni)\n",
    "      uprelu = nn.ReLU(True)\n",
    "      upnorm = nn.BatchNorm2d(nf)\n",
    "\n",
    "      if outermost:\n",
    "          upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                      stride=2, padding=1)\n",
    "          down = [downconv]\n",
    "          up = [uprelu, upconv, nn.Tanh()]\n",
    "          model = down + [submodule] + up\n",
    "      elif innermost:\n",
    "          upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
    "                                      stride=2, padding=1, bias=False)\n",
    "          down = [downrelu, downconv]\n",
    "          up = [uprelu, upconv, upnorm]\n",
    "          model = down + up\n",
    "      else:\n",
    "          upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                      stride=2, padding=1, bias=False)\n",
    "          down = [downrelu, downconv, downnorm]\n",
    "          up = [uprelu, upconv, upnorm]\n",
    "          if dropout: up += [nn.Dropout(0.5)]\n",
    "          model = down + [submodule] + up\n",
    "      self.model = nn.Sequential(*model)\n",
    "\n",
    "  def forward(self, x):\n",
    "      if self.outermost:\n",
    "          return self.model(x)\n",
    "      else:\n",
    "          return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "  def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
    "      super().__init__()\n",
    "      unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
    "      for _ in range(n_down - 5):\n",
    "          unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
    "      out_filters = num_filters * 8\n",
    "      for _ in range(3):\n",
    "          unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
    "          out_filters //= 2\n",
    "      self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.model(x)\n",
    "def init_weights(net, init='norm', gain=0.02):\n",
    "    \n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "            \n",
    "    net.apply(init_func)\n",
    "    return net\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model\n",
    "class PatchDiscriminator(nn.Module):\n",
    "  def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "      super().__init__()\n",
    "      model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "      model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
    "                        for i in range(n_down)]\n",
    "      model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)]\n",
    "      self.model = nn.Sequential(*model)                                                   \n",
    "\n",
    "  def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): \n",
    "      layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          \n",
    "      if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "      if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.model(x)\n",
    "class GANLoss(nn.Module):\n",
    "  def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "      super().__init__()\n",
    "      self.register_buffer('real_label', torch.tensor(real_label))\n",
    "      self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "      if gan_mode == 'vanilla':\n",
    "          self.loss = nn.BCEWithLogitsLoss()\n",
    "      elif gan_mode == 'lsgan':\n",
    "          self.loss = nn.MSELoss()\n",
    "\n",
    "  def get_labels(self, preds, target_is_real):\n",
    "      if target_is_real:\n",
    "          labels = self.real_label\n",
    "      else:\n",
    "          labels = self.fake_label\n",
    "      return labels.expand_as(preds)\n",
    "\n",
    "  def __call__(self, preds, target_is_real):\n",
    "      labels = self.get_labels(preds, target_is_real)\n",
    "      loss = self.loss(preds, labels)\n",
    "      return loss\n",
    "class MainModel(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=1e-4, lr_D=1e-4, \n",
    "                 beta1=0.40, beta2=0.9, lambda_L1=90.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if net_G is None:\n",
    "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "    \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.fake_color = self.net_G(self.L)\n",
    "    \n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "    \n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "  L = (L + 1.) * 50.\n",
    "  ab = ab * 110.\n",
    "  Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "  rgb_imgs = []\n",
    "  for img in Lab:\n",
    "      img_rgb = lab2rgb(img)\n",
    "      rgb_imgs.append(img_rgb)\n",
    "  return np.stack(rgb_imgs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f4981-b7e3-4513-8ede-182c7a17e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model_state_dict = torch.load(\"C:\\\\Users\\\\dhanr\\\\Downloads\\\\coloration.pt\", map_location=device)\n",
    "model = MainModel()\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf297ad0-95aa-4405-844e-57474577b78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Image Converter\")\n",
    "root.geometry('800x800')\n",
    "canvas = tk.Canvas(root, width=600, height=600)\n",
    "canvas.pack()\n",
    "def browse_file():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    input_image = Image.open(file_path)\n",
    "    input_image = input_image.resize((256, 256))\n",
    "    input_image_tk = ImageTk.PhotoImage(input_image)\n",
    "    canvas.create_image(0, 0, anchor=\"nw\", image=input_image_tk)\n",
    "    canvas.input_image_tk = input_image_tk\n",
    "    canvas.create_text(100,300,text=(\"B/W Image(Input)\"),fill=\"black\",font=(\"Helvetica 10 bold\"))\n",
    "    f_path = glob.glob(file_path)\n",
    "    file_dl = make_dataloaders(paths=f_path)\n",
    "    data = next(iter(file_dl))\n",
    "    ls,ab = data['L'],data['ab']\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    fake_imgs[0] = ((fake_imgs[0] - fake_imgs[0].min()) / (fake_imgs[0].max() - fake_imgs[0].min())) * 255\n",
    "    img = Image.fromarray(np.uint8(fake_imgs[0]))\n",
    "    photo_img = ImageTk.PhotoImage(img)\n",
    "    canvas.create_image(256, 0, anchor=\"nw\", image=photo_img)\n",
    "    canvas.photo_img = photo_img\n",
    "    canvas.create_text(400,300,text=(\"Color Image(Output)\"),fill=\"black\",font=(\"Helvetica 10 bold\"))\n",
    "\n",
    "button = tk.Button(root, text=\"Browse input file\", command=browse_file)\n",
    "button.pack()\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
